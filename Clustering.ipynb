{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from kmodes.kprototypes import KPrototypes\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Import the dataset and Removing the customer id column from the dataset as it provides no useful data, no split for k-means\n",
        "dataset = pd.read_csv(\"marketing_campaign.csv\")\n",
        "dataset.head()\n",
        "\n",
        "n_row,n_col = dataset.shape\n",
        "print(\"The number of rows in dataset are {0} and the number of columns are {1} \".format(n_row,n_col))\n",
        "\n",
        "# Information on dataset before removing unnecessary columns\n",
        "\n",
        "dataset.info()\n",
        "dataset.describe(include='all')\n",
        "\n",
        "# The columns for Z_CostContact and Z_Revenue provide no useful information for my analysis, therefore I remove them.\n",
        "dataset.drop(columns=[\"ID\", \"Z_CostContact\", \"Z_Revenue\"], inplace=True, errors='ignore')\n",
        "\n",
        "\n",
        "# information on dataset after removing unnecessary columns\n",
        "dataset.info()\n",
        "\n",
        "# Having a mix data type, Dt_Customer is data type object\n",
        "# Education and Martial_Status are categorical features\n",
        "# Income has missing values\n",
        "\n",
        "# Exploring the categorical features\n",
        "print(dataset[\"Marital_Status\"].value_counts())\n",
        "\n",
        "# Exploring the categorical features\n",
        "print(dataset[\"Marital_Status\"].value_counts())\n",
        "print(dataset[\"Education\"].value_counts())\n",
        "\n",
        "# Feature Engineering\n",
        "dataset[\"Marital_Status\"].replace({\"Alone\":\"Single\",\"Absurd\":\"Single\", \"YOLO\":\"Single\"},inplace=True)\n",
        "\n",
        "# Replace data of birth with age\n",
        "\n",
        "dataset[\"Year_Birth\"] = 2022-dataset[\"Year_Birth\"]\n",
        "dataset.rename(columns={\"Year_Birth\":\"Age\"},inplace = True)\n",
        "dataset.head()\n",
        "\n",
        "# total Spending on all items\n",
        "dataset[\"Total_Spent\"] = dataset[\"MntWines\"]+dataset[\"MntFruits\"]+dataset[\"MntMeatProducts\"]+dataset[\"MntFishProducts\"]+dataset[\"MntSweetProducts\"]+dataset[\"MntGoldProds\"]\n",
        "\n",
        "# Creating a new feature showing the number of days of customer engagement\n",
        "dataset[\"Dt_Customer\"] = pd.to_datetime(dataset.Dt_Customer)\n",
        "newest_customer = dataset[\"Dt_Customer\"].max()\n",
        "dataset[\"newest_customer\"] = newest_customer\n",
        "dataset[\"days_engaged\"]=(dataset[\"newest_customer\"] - dataset[\"Dt_Customer\"]).dt.days\n",
        "print(dataset[\"days_engaged\"])\n",
        "dataset.drop(columns=[\"Dt_Customer\",\"newest_customer\"],inplace=True)\n",
        "dataset.describe()\n",
        "\n",
        "# Data Cleaning process in order to target NaN values\n",
        "dataset.isna().sum\n",
        "dataset.dropna(inplace = True)\n",
        "\n",
        "# Checking on the relevant features\n",
        "plt.figure()\n",
        "cols_to_plot = [\"Income\",\"Age\",\"Total_Spent\"]\n",
        "sns.pairplot(dataset[cols_to_plot], diag_kind = \"kde\", diag_kws = {\"color\":\"g\"}, plot_kws={\"color\":\"y\"})\n",
        "plt.show()\n",
        "\n",
        "# dropping the outliers\n",
        "dataset = dataset[dataset[\"Age\"]<100]\n",
        "dataset = dataset[(dataset[\"Income\"]<600000)]\n",
        "\n",
        "# Number of samples after cleaning\n",
        "print(len(dataset))\n",
        "\n",
        "# Show casing the correlation among the features\n",
        "numeric_dataset = dataset.select_dtypes(include=['int64', 'float64'])\n",
        "plt.figure(figsize = (16,9))\n",
        "sns.heatmap(dataset.corr(),cmap=\"viridis\",annot = True)\n",
        "plt.title(\"Correlation matrix\")\n",
        "plt.show()\n",
        "\n",
        "# encoding ordinal features using OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
        "education_order = [\"Basic\",\"2n Cycle\",\"Graduation\",\"Master\",\"PhD\"]\n",
        "oe = OrdinalEncoder(categories = [education_order], dtype = int)\n",
        "education_oe = oe.fit_transform(dataset[[\"Education\"]])\n",
        "dataset_enc = dataset.assign(Education_encode=education_oe)\n",
        "print(dataset_enc.shape)\n",
        "print(dataset_enc[[\"Education\",\"Education_encode\"]])\n",
        "\n",
        "ohe = OneHotEncoder(dtype=\"int\")\n",
        "Marital_ohe = ohe.fit_transform(dataset[[\"Marital_Status\"]])\n",
        "Marital_ohe = pd.DataFrame(data=Marital_ohe.toarray(),columns=ohe.get_feature_names_out([\"Marital_Status\"]), index=dataset.index,)\n",
        "dataset_enc = pd.concat([dataset_enc,Marital_ohe],axis=1)\n",
        "dataset_enc.drop(columns=[\"Marital_Status\",\"Education\"],inplace=True)\n",
        "dataset_enc.info()\n",
        "\n",
        "\n",
        "binary_columns = [\"Marital_Status_Divorced\",\"Marital_Status_Married\",\"Marital_Status_Single\",\"Marital_Status_Together\",\"AcceptedCmp3\",\"AcceptedCmp4\",\"AcceptedCmp5\",\"AcceptedCmp1\",\"AcceptedCmp2\",\"Complain\",\"Response\"]\n",
        "dataset_to_scaler = dataset_enc.drop(columns = binary_columns)\n",
        "scaler = StandardScaler().fit_transform(dataset_to_scaler)\n",
        "scaled_dataset = pd.DataFrame(scaler,columns = dataset_to_scaler.columns)\n",
        "binary_series = dataset_enc[binary_columns]\n",
        "scaled_dataset = pd.concat([scaled_dataset,binary_series],axis=1)\n",
        "scaled_dataset.isna().sum()\n",
        "scaled_dataset = scaled_dataset.fillna(0)\n",
        "\n",
        "# Dimensionality Reduction with PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 3)\n",
        "pca.fit(scaled_dataset)\n",
        "PCA_dataset = pd.DataFrame(pca.transform(scaled_dataset),columns =([\"feature1\",\"feature2\",\"feature3\"]))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.axes(projection=\"3d\").scatter(PCA_dataset[\"feature1\"],PCA_dataset[\"feature2\"],PCA_dataset[\"feature3\"])\n",
        "plt.axes(projection=\"3d\").scatter(PCA_dataset[\"feature1\"],PCA_dataset[\"feature2\"],PCA_dataset[\"feature3\"])\n",
        "plt.title(\"A 3D Projection of Data In Reduced Dimension\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Clustering\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "Elbow_M = KElbowVisualizer(KMeans(),k=(2,11))\n",
        "Elbow_M.fit(PCA_dataset)\n",
        "Elbow_M.show()\n",
        "\n",
        "# Using elbow curve to find the optimum number of clusters\n",
        "# The Agglomerative Clustering model\n",
        "\n",
        "AC = AgglomerativeClustering(n_clusters=4)\n",
        "yhat_AC = AC.fit_predict(PCA_dataset)\n",
        "PCA_dataset[\"Clusters\"] = yhat_AC\n",
        "scaled_dataset[\"Clusters\"] = yhat_AC\n",
        "\n",
        "# Plotting Clusters\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.axes(projection=\"3d\").scatter(PCA_dataset[\"feature1\"],PCA_dataset[\"feature2\"],PCA_dataset[\"feature3\"])\n",
        "plt.title(\"The Clusters by Agglomerative Model\")\n",
        "\n",
        "sns.scatterplot(data = scaled_dataset,x=scaled_dataset[\"Total_Spent\"], y = scaled_dataset[\"Income\"], hue = scaled_dataset[\"Clusters\"])\n",
        "plt.title(\"Cluster's Profile Based on Income and Total Spending\")\n",
        "\n",
        "# Clustering using K-Means Model\n",
        "\n",
        "kmeans = KMeans(n_clusters = 4, init = \"k-means++\", random_state = 50)\n",
        "# fit model and predict clusters\n",
        "labels = kmeans.fit_predict(PCA_dataset)\n",
        "PCA_dataset[\"Clusters\"] = labels\n",
        "# Adding the Clusters feature to the original dataframe\n",
        "scaled_dataset[\"Clusters\"] = labels\n",
        "\n",
        "# plotting the clusters\n",
        "fig = plt.fig(figsize=(10,8))\n",
        "ax = plt.subplot(111,projection=\"3d\",label = \"bla\")\n",
        "ax.scatter(PCA_dataset[\"feature1\"],PCA_dataset[\"feature2\"],PCA_dataset[\"feature3\"], s = 40, c = PCA_dataset[\"Clusters\"])\n",
        "ax.set_title(\"Clustering by K-Means model\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tidmkfLFRR0Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}